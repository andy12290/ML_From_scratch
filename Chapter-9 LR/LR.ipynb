{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lets try small example to use the LR\n",
    "from math import exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prediction(row, coefficients):\n",
    "    yhat = coefficients[0] # slope of equation\n",
    "    for i in range(len(row)-1):\n",
    "        yhat += coefficients[i+1] * row[i]\n",
    "    return 1.0/ (1.0+exp(yhat))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test predictions\n",
    "dataset = [[2.7810836,2.550537003,0],\n",
    "[1.465489372,2.362125076,0],\n",
    "[3.396561688,4.400293529,0],\n",
    "[1.38807019,1.850220317,0],\n",
    "[3.06407232,3.005305973,0],\n",
    "[7.627531214,2.759262235,1],\n",
    "[5.332441248,2.088626775,1],\n",
    "[6.922596716,1.77106367,1],\n",
    "[8.675418651,-0.242068655,1],\n",
    "[7.673756466,3.508563011,1]]\n",
    "coef = [-0.406605464, 0.852573316, -1.104746259]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected=0.000, Predicted=0.701 [1]\n",
      "Expected=0.000, Predicted=0.854 [1]\n",
      "Expected=0.000, Predicted=0.915 [1]\n",
      "Expected=0.000, Predicted=0.780 [1]\n",
      "Expected=0.000, Predicted=0.753 [1]\n",
      "Expected=1.000, Predicted=0.045 [0]\n",
      "Expected=1.000, Predicted=0.138 [0]\n",
      "Expected=1.000, Predicted=0.028 [0]\n",
      "Expected=1.000, Predicted=0.001 [0]\n",
      "Expected=1.000, Predicted=0.095 [0]\n"
     ]
    }
   ],
   "source": [
    "for row in dataset:\n",
    "    yhat = prediction(row, coef)\n",
    "    print(\"Expected=%.3f, Predicted=%.3f [%d]\" % (row[-1], yhat, round(yhat)))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def coefficients_sgd(train, l_rate, n_epoch):\n",
    "    coef = [ 0.0 for i in range(len(train[0]))] # set the coef for zero as per the number of rows\n",
    "    for epoch in range(n_epoch): # iterate throgh each epoch\n",
    "        sum_error = 0\n",
    "        for row in train:\n",
    "            yhat = prediction(row, coef) # prediction and calculation of yhat\n",
    "            error = row[-1] - yhat # calculation of error\n",
    "            sum_error += error**2\n",
    "            coef[0] = coef[0] + l_rate*error *yhat*(1-yhat) # slop  coef\n",
    "            for i in range(len(row)-1):\n",
    "                coef[i+1] = coef[i+1] + l_rate * error * yhat * (1-yhat) * row[i]\n",
    "        print('>epoch=%d, lrate=%.3f, error=%.3f' % (epoch, l_rate, sum_error))\n",
    "    return coef         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = [[2.7810836,2.550537003,0],\n",
    "[1.465489372,2.362125076,0],\n",
    "[3.396561688,4.400293529,0],\n",
    "[1.38807019,1.850220317,0],\n",
    "[3.06407232,3.005305973,0],\n",
    "[7.627531214,2.759262235,1],\n",
    "[5.332441248,2.088626775,1],\n",
    "[6.922596716,1.77106367,1],\n",
    "[8.675418651,-0.242068655,1],\n",
    "[7.673756466,3.508563011,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">epoch=0, lrate=0.300, error=2.732\n",
      ">epoch=1, lrate=0.300, error=4.383\n",
      ">epoch=2, lrate=0.300, error=4.654\n",
      ">epoch=3, lrate=0.300, error=4.758\n",
      ">epoch=4, lrate=0.300, error=4.813\n",
      ">epoch=5, lrate=0.300, error=4.847\n",
      ">epoch=6, lrate=0.300, error=4.871\n",
      ">epoch=7, lrate=0.300, error=4.888\n",
      ">epoch=8, lrate=0.300, error=4.901\n",
      ">epoch=9, lrate=0.300, error=4.911\n",
      ">epoch=10, lrate=0.300, error=4.920\n",
      ">epoch=11, lrate=0.300, error=4.927\n",
      ">epoch=12, lrate=0.300, error=4.932\n",
      ">epoch=13, lrate=0.300, error=4.937\n",
      ">epoch=14, lrate=0.300, error=4.941\n",
      ">epoch=15, lrate=0.300, error=4.945\n",
      ">epoch=16, lrate=0.300, error=4.948\n",
      ">epoch=17, lrate=0.300, error=4.951\n",
      ">epoch=18, lrate=0.300, error=4.954\n",
      ">epoch=19, lrate=0.300, error=4.956\n",
      ">epoch=20, lrate=0.300, error=4.958\n",
      ">epoch=21, lrate=0.300, error=4.960\n",
      ">epoch=22, lrate=0.300, error=4.962\n",
      ">epoch=23, lrate=0.300, error=4.963\n",
      ">epoch=24, lrate=0.300, error=4.965\n",
      ">epoch=25, lrate=0.300, error=4.966\n",
      ">epoch=26, lrate=0.300, error=4.967\n",
      ">epoch=27, lrate=0.300, error=4.969\n",
      ">epoch=28, lrate=0.300, error=4.970\n",
      ">epoch=29, lrate=0.300, error=4.971\n",
      ">epoch=30, lrate=0.300, error=4.972\n",
      ">epoch=31, lrate=0.300, error=4.972\n",
      ">epoch=32, lrate=0.300, error=4.973\n",
      ">epoch=33, lrate=0.300, error=4.974\n",
      ">epoch=34, lrate=0.300, error=4.975\n",
      ">epoch=35, lrate=0.300, error=4.976\n",
      ">epoch=36, lrate=0.300, error=4.976\n",
      ">epoch=37, lrate=0.300, error=4.977\n",
      ">epoch=38, lrate=0.300, error=4.977\n",
      ">epoch=39, lrate=0.300, error=4.978\n",
      ">epoch=40, lrate=0.300, error=4.978\n",
      ">epoch=41, lrate=0.300, error=4.979\n",
      ">epoch=42, lrate=0.300, error=4.979\n",
      ">epoch=43, lrate=0.300, error=4.980\n",
      ">epoch=44, lrate=0.300, error=4.980\n",
      ">epoch=45, lrate=0.300, error=4.981\n",
      ">epoch=46, lrate=0.300, error=4.981\n",
      ">epoch=47, lrate=0.300, error=4.982\n",
      ">epoch=48, lrate=0.300, error=4.982\n",
      ">epoch=49, lrate=0.300, error=4.982\n",
      ">epoch=50, lrate=0.300, error=4.983\n",
      ">epoch=51, lrate=0.300, error=4.983\n",
      ">epoch=52, lrate=0.300, error=4.983\n",
      ">epoch=53, lrate=0.300, error=4.984\n",
      ">epoch=54, lrate=0.300, error=4.984\n",
      ">epoch=55, lrate=0.300, error=4.984\n",
      ">epoch=56, lrate=0.300, error=4.984\n",
      ">epoch=57, lrate=0.300, error=4.985\n",
      ">epoch=58, lrate=0.300, error=4.985\n",
      ">epoch=59, lrate=0.300, error=4.985\n",
      ">epoch=60, lrate=0.300, error=4.985\n",
      ">epoch=61, lrate=0.300, error=4.986\n",
      ">epoch=62, lrate=0.300, error=4.986\n",
      ">epoch=63, lrate=0.300, error=4.986\n",
      ">epoch=64, lrate=0.300, error=4.986\n",
      ">epoch=65, lrate=0.300, error=4.986\n",
      ">epoch=66, lrate=0.300, error=4.987\n",
      ">epoch=67, lrate=0.300, error=4.987\n",
      ">epoch=68, lrate=0.300, error=4.987\n",
      ">epoch=69, lrate=0.300, error=4.987\n",
      ">epoch=70, lrate=0.300, error=4.987\n",
      ">epoch=71, lrate=0.300, error=4.988\n",
      ">epoch=72, lrate=0.300, error=4.988\n",
      ">epoch=73, lrate=0.300, error=4.988\n",
      ">epoch=74, lrate=0.300, error=4.988\n",
      ">epoch=75, lrate=0.300, error=4.988\n",
      ">epoch=76, lrate=0.300, error=4.988\n",
      ">epoch=77, lrate=0.300, error=4.989\n",
      ">epoch=78, lrate=0.300, error=4.989\n",
      ">epoch=79, lrate=0.300, error=4.989\n",
      ">epoch=80, lrate=0.300, error=4.989\n",
      ">epoch=81, lrate=0.300, error=4.989\n",
      ">epoch=82, lrate=0.300, error=4.989\n",
      ">epoch=83, lrate=0.300, error=4.989\n",
      ">epoch=84, lrate=0.300, error=4.989\n",
      ">epoch=85, lrate=0.300, error=4.990\n",
      ">epoch=86, lrate=0.300, error=4.990\n",
      ">epoch=87, lrate=0.300, error=4.990\n",
      ">epoch=88, lrate=0.300, error=4.990\n",
      ">epoch=89, lrate=0.300, error=4.990\n",
      ">epoch=90, lrate=0.300, error=4.990\n",
      ">epoch=91, lrate=0.300, error=4.990\n",
      ">epoch=92, lrate=0.300, error=4.990\n",
      ">epoch=93, lrate=0.300, error=4.990\n",
      ">epoch=94, lrate=0.300, error=4.991\n",
      ">epoch=95, lrate=0.300, error=4.991\n",
      ">epoch=96, lrate=0.300, error=4.991\n",
      ">epoch=97, lrate=0.300, error=4.991\n",
      ">epoch=98, lrate=0.300, error=4.991\n",
      ">epoch=99, lrate=0.300, error=4.991\n",
      "[-0.7445831528974612, -1.335286211966297, -1.7135663214997658]\n"
     ]
    }
   ],
   "source": [
    "l_rate = 0.3\n",
    "n_epoch = 100\n",
    "coef = coefficients_sgd(dataset, l_rate, n_epoch)\n",
    "print(coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">epoch=0, lrate=0.100, error=2.014\n",
      ">epoch=1, lrate=0.100, error=2.762\n",
      ">epoch=2, lrate=0.100, error=3.609\n",
      ">epoch=3, lrate=0.100, error=4.076\n",
      ">epoch=4, lrate=0.100, error=4.322\n",
      ">epoch=5, lrate=0.100, error=4.467\n",
      ">epoch=6, lrate=0.100, error=4.562\n",
      ">epoch=7, lrate=0.100, error=4.628\n",
      ">epoch=8, lrate=0.100, error=4.676\n",
      ">epoch=9, lrate=0.100, error=4.714\n",
      ">epoch=10, lrate=0.100, error=4.743\n",
      ">epoch=11, lrate=0.100, error=4.767\n",
      ">epoch=12, lrate=0.100, error=4.787\n",
      ">epoch=13, lrate=0.100, error=4.804\n",
      ">epoch=14, lrate=0.100, error=4.818\n",
      ">epoch=15, lrate=0.100, error=4.830\n",
      ">epoch=16, lrate=0.100, error=4.841\n",
      ">epoch=17, lrate=0.100, error=4.851\n",
      ">epoch=18, lrate=0.100, error=4.859\n",
      ">epoch=19, lrate=0.100, error=4.866\n",
      ">epoch=20, lrate=0.100, error=4.873\n",
      ">epoch=21, lrate=0.100, error=4.879\n",
      ">epoch=22, lrate=0.100, error=4.885\n",
      ">epoch=23, lrate=0.100, error=4.890\n",
      ">epoch=24, lrate=0.100, error=4.894\n",
      ">epoch=25, lrate=0.100, error=4.898\n",
      ">epoch=26, lrate=0.100, error=4.902\n",
      ">epoch=27, lrate=0.100, error=4.906\n",
      ">epoch=28, lrate=0.100, error=4.909\n",
      ">epoch=29, lrate=0.100, error=4.912\n",
      ">epoch=30, lrate=0.100, error=4.915\n",
      ">epoch=31, lrate=0.100, error=4.918\n",
      ">epoch=32, lrate=0.100, error=4.920\n",
      ">epoch=33, lrate=0.100, error=4.923\n",
      ">epoch=34, lrate=0.100, error=4.925\n",
      ">epoch=35, lrate=0.100, error=4.927\n",
      ">epoch=36, lrate=0.100, error=4.929\n",
      ">epoch=37, lrate=0.100, error=4.931\n",
      ">epoch=38, lrate=0.100, error=4.933\n",
      ">epoch=39, lrate=0.100, error=4.935\n",
      ">epoch=40, lrate=0.100, error=4.936\n",
      ">epoch=41, lrate=0.100, error=4.938\n",
      ">epoch=42, lrate=0.100, error=4.939\n",
      ">epoch=43, lrate=0.100, error=4.940\n",
      ">epoch=44, lrate=0.100, error=4.942\n",
      ">epoch=45, lrate=0.100, error=4.943\n",
      ">epoch=46, lrate=0.100, error=4.944\n",
      ">epoch=47, lrate=0.100, error=4.945\n",
      ">epoch=48, lrate=0.100, error=4.947\n",
      ">epoch=49, lrate=0.100, error=4.948\n",
      ">epoch=50, lrate=0.100, error=4.949\n",
      ">epoch=51, lrate=0.100, error=4.950\n",
      ">epoch=52, lrate=0.100, error=4.951\n",
      ">epoch=53, lrate=0.100, error=4.952\n",
      ">epoch=54, lrate=0.100, error=4.952\n",
      ">epoch=55, lrate=0.100, error=4.953\n",
      ">epoch=56, lrate=0.100, error=4.954\n",
      ">epoch=57, lrate=0.100, error=4.955\n",
      ">epoch=58, lrate=0.100, error=4.956\n",
      ">epoch=59, lrate=0.100, error=4.956\n",
      ">epoch=60, lrate=0.100, error=4.957\n",
      ">epoch=61, lrate=0.100, error=4.958\n",
      ">epoch=62, lrate=0.100, error=4.958\n",
      ">epoch=63, lrate=0.100, error=4.959\n",
      ">epoch=64, lrate=0.100, error=4.960\n",
      ">epoch=65, lrate=0.100, error=4.960\n",
      ">epoch=66, lrate=0.100, error=4.961\n",
      ">epoch=67, lrate=0.100, error=4.961\n",
      ">epoch=68, lrate=0.100, error=4.962\n",
      ">epoch=69, lrate=0.100, error=4.963\n",
      ">epoch=70, lrate=0.100, error=4.963\n",
      ">epoch=71, lrate=0.100, error=4.964\n",
      ">epoch=72, lrate=0.100, error=4.964\n",
      ">epoch=73, lrate=0.100, error=4.965\n",
      ">epoch=74, lrate=0.100, error=4.965\n",
      ">epoch=75, lrate=0.100, error=4.965\n",
      ">epoch=76, lrate=0.100, error=4.966\n",
      ">epoch=77, lrate=0.100, error=4.966\n",
      ">epoch=78, lrate=0.100, error=4.967\n",
      ">epoch=79, lrate=0.100, error=4.967\n",
      ">epoch=80, lrate=0.100, error=4.968\n",
      ">epoch=81, lrate=0.100, error=4.968\n",
      ">epoch=82, lrate=0.100, error=4.968\n",
      ">epoch=83, lrate=0.100, error=4.969\n",
      ">epoch=84, lrate=0.100, error=4.969\n",
      ">epoch=85, lrate=0.100, error=4.969\n",
      ">epoch=86, lrate=0.100, error=4.970\n",
      ">epoch=87, lrate=0.100, error=4.970\n",
      ">epoch=88, lrate=0.100, error=4.970\n",
      ">epoch=89, lrate=0.100, error=4.971\n",
      ">epoch=90, lrate=0.100, error=4.971\n",
      ">epoch=91, lrate=0.100, error=4.971\n",
      ">epoch=92, lrate=0.100, error=4.972\n",
      ">epoch=93, lrate=0.100, error=4.972\n",
      ">epoch=94, lrate=0.100, error=4.972\n",
      ">epoch=95, lrate=0.100, error=4.973\n",
      ">epoch=96, lrate=0.100, error=4.973\n",
      ">epoch=97, lrate=0.100, error=4.973\n",
      ">epoch=98, lrate=0.100, error=4.973\n",
      ">epoch=99, lrate=0.100, error=4.974\n",
      "[-0.6111378540841587, -1.0312260947124907, -1.4727009206449442]\n"
     ]
    }
   ],
   "source": [
    "# Lets try different learning rate\n",
    "l_rate = 0.1\n",
    "n_epoch = 100\n",
    "coef = coefficients_sgd(dataset, l_rate, n_epoch)\n",
    "print(coef)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression Case study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from random import seed\n",
    "from random import randrange\n",
    "from csv import reader\n",
    "from math import exp\n",
    "\n",
    "# Load csv file\n",
    "def load_csv(filename):\n",
    "    dataset = []\n",
    "    file = open(filename, \"r\")\n",
    "    csv_reader = reader(file)\n",
    "    for row in csv_reader:\n",
    "        if not row:\n",
    "            continue\n",
    "        dataset.append(row)\n",
    "    return dataset  \n",
    "\n",
    "\n",
    "# convert string to column\n",
    "def str_column_to_float(dataset, column):\n",
    "    for row in dataset:\n",
    "        row[column] = float(row[column].strip()) # this is only for single row\n",
    "        \n",
    "        \n",
    "#  find the min and max values\n",
    "def dataset_minmax(dataset):\n",
    "    minmax = []\n",
    "    for i in range(len(dataset[0])):\n",
    "        col_values = [row[i] for row in dataset]\n",
    "        value_min = min(col_values)\n",
    "        value_max = max(col_values)\n",
    "        minmax.append([value_min, value_max])\n",
    "    return minmax\n",
    "\n",
    "def normalize_dataset(dataset, minmax):\n",
    "    for row in dataset:\n",
    "        for i in range(len(row)):\n",
    "            row[i] = (row[i] - minmax[i][0]) / (minmax[i][1] - minmax[i][0])\n",
    "    \n",
    "# Cross validation\n",
    "def cross_validation_split(dataset, n_folds):\n",
    "    dataset_split = []\n",
    "    dataset_copy = list(dataset)\n",
    "    fold_size = int(len(dataset) / n_folds) # 10 records, fold size 3 , 3\n",
    "    for i in range(n_folds):\n",
    "        fold = []\n",
    "        while len(fold) < fold_size:\n",
    "            index = randrange(len(dataset_copy)) # index select any records from dataset copy\n",
    "            fold.append(dataset_copy.pop(index))\n",
    "        dataset_split.append(fold)\n",
    "    return dataset_split  \n",
    "\n",
    "\n",
    "# Calculate accuracy\n",
    "def accuracy_metric(actual, predicted):\n",
    "    correct = 0\n",
    "    for row in range(len(actual)):\n",
    "        if actual[i] == predicted[i]:\n",
    "            correct += 1\n",
    "     \n",
    "    return correct / float(len(actual)) * 100 # correct number of records\n",
    "\n",
    "\n",
    "# Evaluate the algorithm using the cross validation split\n",
    "def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n",
    "    folds = cross_validation_split(dataset, n_folds) # will get number of folds 10 records 3 n folds = 3\n",
    "    scores = []\n",
    "    for fold in folds:\n",
    "        train_set = list(folds)\n",
    "        train_set.remove(fold)\n",
    "        train_set = sum(train_set, []) # SUM 2 FOLDS into thr train and one for test\n",
    "        test_set = []\n",
    "        for row in fold:\n",
    "            row_copy = list(row)\n",
    "            test_set.append(row_copy)\n",
    "        predicted = algorithm(train_set, test_set, * args)\n",
    "        actual =  [row[-1] for row in fold]\n",
    "        accuracy = accuracy_metric(actual, predicted)\n",
    "        scores.append(accuracy)\n",
    "    return scores\n",
    "\n",
    "    # predict the \n",
    "def predict(row, coefficients):\n",
    "    yhat = coefficients[0] # slope of equation\n",
    "    for i in range(len(row)-1):\n",
    "        yhat += coefficients[i+1] * row[i]\n",
    "    return 1.0/ (1.0+exp(yhat)) \n",
    "\n",
    "# coeffiencet calculation\n",
    "def coefficients_sgd(train, l_rate, n_epoch):\n",
    "    coef = [ 0.0 for i in range(len(train[0]))] # set the coef for zero as per the number of rows\n",
    "    for epoch in range(n_epoch): # iterate throgh each epoch\n",
    "        sum_error = 0\n",
    "        for row in train:\n",
    "            yhat = predict(row, coef) # prediction and calculation of yhat\n",
    "            error = row[-1] - yhat # calculation of error\n",
    "            sum_error += error**2\n",
    "            coef[0] = coef[0] + l_rate*error *yhat*(1-yhat) # slop  coef\n",
    "            for i in range(len(row)-1):\n",
    "                coef[i+1] = coef[i+1] + l_rate * error * yhat * (1-yhat) * row[i]\n",
    "        print('>epoch=%d, lrate=%.3f, error=%.3f' % (epoch, l_rate, sum_error))\n",
    "    return coef         \n",
    "        \n",
    "# define logistic regression\n",
    "\n",
    "def logistic_regression(train, test, l_rate, n_epoch):\n",
    "    prediction = []\n",
    "    coef = coefficients_sgd(train, l_rate, n_epoch)\n",
    "    for row in test:\n",
    "        yhat = predict(row, coef)\n",
    "        yhat = round(yhat)\n",
    "        prediction.append(yhat)\n",
    "    return prediction   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">epoch=0, lrate=0.100, error=331.687\n",
      ">epoch=1, lrate=0.100, error=392.734\n",
      ">epoch=2, lrate=0.100, error=396.924\n",
      ">epoch=3, lrate=0.100, error=398.486\n",
      ">epoch=4, lrate=0.100, error=399.308\n",
      ">epoch=5, lrate=0.100, error=399.816\n",
      ">epoch=6, lrate=0.100, error=400.161\n",
      ">epoch=7, lrate=0.100, error=400.412\n",
      ">epoch=8, lrate=0.100, error=400.601\n",
      ">epoch=9, lrate=0.100, error=400.750\n",
      ">epoch=10, lrate=0.100, error=400.870\n",
      ">epoch=11, lrate=0.100, error=400.969\n",
      ">epoch=12, lrate=0.100, error=401.052\n",
      ">epoch=13, lrate=0.100, error=401.122\n",
      ">epoch=14, lrate=0.100, error=401.183\n",
      ">epoch=15, lrate=0.100, error=401.235\n",
      ">epoch=16, lrate=0.100, error=401.282\n",
      ">epoch=17, lrate=0.100, error=401.323\n",
      ">epoch=18, lrate=0.100, error=401.359\n",
      ">epoch=19, lrate=0.100, error=401.392\n",
      ">epoch=20, lrate=0.100, error=401.421\n",
      ">epoch=21, lrate=0.100, error=401.448\n",
      ">epoch=22, lrate=0.100, error=401.472\n",
      ">epoch=23, lrate=0.100, error=401.494\n",
      ">epoch=24, lrate=0.100, error=401.515\n",
      ">epoch=25, lrate=0.100, error=401.534\n",
      ">epoch=26, lrate=0.100, error=401.551\n",
      ">epoch=27, lrate=0.100, error=401.567\n",
      ">epoch=28, lrate=0.100, error=401.582\n",
      ">epoch=29, lrate=0.100, error=401.596\n",
      ">epoch=30, lrate=0.100, error=401.609\n",
      ">epoch=31, lrate=0.100, error=401.621\n",
      ">epoch=32, lrate=0.100, error=401.633\n",
      ">epoch=33, lrate=0.100, error=401.644\n",
      ">epoch=34, lrate=0.100, error=401.654\n",
      ">epoch=35, lrate=0.100, error=401.664\n",
      ">epoch=36, lrate=0.100, error=401.673\n",
      ">epoch=37, lrate=0.100, error=401.681\n",
      ">epoch=38, lrate=0.100, error=401.689\n",
      ">epoch=39, lrate=0.100, error=401.697\n",
      ">epoch=40, lrate=0.100, error=401.704\n",
      ">epoch=41, lrate=0.100, error=401.711\n",
      ">epoch=42, lrate=0.100, error=401.718\n",
      ">epoch=43, lrate=0.100, error=401.724\n",
      ">epoch=44, lrate=0.100, error=401.731\n",
      ">epoch=45, lrate=0.100, error=401.736\n",
      ">epoch=46, lrate=0.100, error=401.742\n",
      ">epoch=47, lrate=0.100, error=401.747\n",
      ">epoch=48, lrate=0.100, error=401.752\n",
      ">epoch=49, lrate=0.100, error=401.757\n",
      ">epoch=50, lrate=0.100, error=401.762\n",
      ">epoch=51, lrate=0.100, error=401.767\n",
      ">epoch=52, lrate=0.100, error=401.771\n",
      ">epoch=53, lrate=0.100, error=401.775\n",
      ">epoch=54, lrate=0.100, error=401.779\n",
      ">epoch=55, lrate=0.100, error=401.783\n",
      ">epoch=56, lrate=0.100, error=401.787\n",
      ">epoch=57, lrate=0.100, error=401.790\n",
      ">epoch=58, lrate=0.100, error=401.794\n",
      ">epoch=59, lrate=0.100, error=401.797\n",
      ">epoch=60, lrate=0.100, error=401.801\n",
      ">epoch=61, lrate=0.100, error=401.804\n",
      ">epoch=62, lrate=0.100, error=401.807\n",
      ">epoch=63, lrate=0.100, error=401.810\n",
      ">epoch=64, lrate=0.100, error=401.813\n",
      ">epoch=65, lrate=0.100, error=401.816\n",
      ">epoch=66, lrate=0.100, error=401.818\n",
      ">epoch=67, lrate=0.100, error=401.821\n",
      ">epoch=68, lrate=0.100, error=401.824\n",
      ">epoch=69, lrate=0.100, error=401.826\n",
      ">epoch=70, lrate=0.100, error=401.828\n",
      ">epoch=71, lrate=0.100, error=401.831\n",
      ">epoch=72, lrate=0.100, error=401.833\n",
      ">epoch=73, lrate=0.100, error=401.835\n",
      ">epoch=74, lrate=0.100, error=401.837\n",
      ">epoch=75, lrate=0.100, error=401.840\n",
      ">epoch=76, lrate=0.100, error=401.842\n",
      ">epoch=77, lrate=0.100, error=401.844\n",
      ">epoch=78, lrate=0.100, error=401.846\n",
      ">epoch=79, lrate=0.100, error=401.847\n",
      ">epoch=80, lrate=0.100, error=401.849\n",
      ">epoch=81, lrate=0.100, error=401.851\n",
      ">epoch=82, lrate=0.100, error=401.853\n",
      ">epoch=83, lrate=0.100, error=401.855\n",
      ">epoch=84, lrate=0.100, error=401.856\n",
      ">epoch=85, lrate=0.100, error=401.858\n",
      ">epoch=86, lrate=0.100, error=401.860\n",
      ">epoch=87, lrate=0.100, error=401.861\n",
      ">epoch=88, lrate=0.100, error=401.863\n",
      ">epoch=89, lrate=0.100, error=401.864\n",
      ">epoch=90, lrate=0.100, error=401.866\n",
      ">epoch=91, lrate=0.100, error=401.867\n",
      ">epoch=92, lrate=0.100, error=401.868\n",
      ">epoch=93, lrate=0.100, error=401.870\n",
      ">epoch=94, lrate=0.100, error=401.871\n",
      ">epoch=95, lrate=0.100, error=401.872\n",
      ">epoch=96, lrate=0.100, error=401.874\n",
      ">epoch=97, lrate=0.100, error=401.875\n",
      ">epoch=98, lrate=0.100, error=401.876\n",
      ">epoch=99, lrate=0.100, error=401.877\n",
      ">epoch=0, lrate=0.100, error=325.570\n",
      ">epoch=1, lrate=0.100, error=384.705\n",
      ">epoch=2, lrate=0.100, error=388.904\n",
      ">epoch=3, lrate=0.100, error=390.470\n",
      ">epoch=4, lrate=0.100, error=391.295\n",
      ">epoch=5, lrate=0.100, error=391.804\n",
      ">epoch=6, lrate=0.100, error=392.151\n",
      ">epoch=7, lrate=0.100, error=392.403\n",
      ">epoch=8, lrate=0.100, error=392.593\n",
      ">epoch=9, lrate=0.100, error=392.743\n",
      ">epoch=10, lrate=0.100, error=392.864\n",
      ">epoch=11, lrate=0.100, error=392.963\n",
      ">epoch=12, lrate=0.100, error=393.046\n",
      ">epoch=13, lrate=0.100, error=393.117\n",
      ">epoch=14, lrate=0.100, error=393.177\n",
      ">epoch=15, lrate=0.100, error=393.230\n",
      ">epoch=16, lrate=0.100, error=393.277\n",
      ">epoch=17, lrate=0.100, error=393.318\n",
      ">epoch=18, lrate=0.100, error=393.354\n",
      ">epoch=19, lrate=0.100, error=393.387\n",
      ">epoch=20, lrate=0.100, error=393.417\n",
      ">epoch=21, lrate=0.100, error=393.444\n",
      ">epoch=22, lrate=0.100, error=393.468\n",
      ">epoch=23, lrate=0.100, error=393.490\n",
      ">epoch=24, lrate=0.100, error=393.511\n",
      ">epoch=25, lrate=0.100, error=393.530\n",
      ">epoch=26, lrate=0.100, error=393.547\n",
      ">epoch=27, lrate=0.100, error=393.564\n",
      ">epoch=28, lrate=0.100, error=393.579\n",
      ">epoch=29, lrate=0.100, error=393.593\n",
      ">epoch=30, lrate=0.100, error=393.606\n",
      ">epoch=31, lrate=0.100, error=393.618\n",
      ">epoch=32, lrate=0.100, error=393.630\n",
      ">epoch=33, lrate=0.100, error=393.641\n",
      ">epoch=34, lrate=0.100, error=393.651\n",
      ">epoch=35, lrate=0.100, error=393.661\n",
      ">epoch=36, lrate=0.100, error=393.670\n",
      ">epoch=37, lrate=0.100, error=393.678\n",
      ">epoch=38, lrate=0.100, error=393.687\n",
      ">epoch=39, lrate=0.100, error=393.694\n",
      ">epoch=40, lrate=0.100, error=393.702\n",
      ">epoch=41, lrate=0.100, error=393.709\n",
      ">epoch=42, lrate=0.100, error=393.716\n",
      ">epoch=43, lrate=0.100, error=393.722\n",
      ">epoch=44, lrate=0.100, error=393.728\n",
      ">epoch=45, lrate=0.100, error=393.734\n",
      ">epoch=46, lrate=0.100, error=393.740\n",
      ">epoch=47, lrate=0.100, error=393.745\n",
      ">epoch=48, lrate=0.100, error=393.750\n",
      ">epoch=49, lrate=0.100, error=393.755\n",
      ">epoch=50, lrate=0.100, error=393.760\n",
      ">epoch=51, lrate=0.100, error=393.764\n",
      ">epoch=52, lrate=0.100, error=393.769\n",
      ">epoch=53, lrate=0.100, error=393.773\n",
      ">epoch=54, lrate=0.100, error=393.777\n",
      ">epoch=55, lrate=0.100, error=393.781\n",
      ">epoch=56, lrate=0.100, error=393.785\n",
      ">epoch=57, lrate=0.100, error=393.788\n",
      ">epoch=58, lrate=0.100, error=393.792\n",
      ">epoch=59, lrate=0.100, error=393.795\n",
      ">epoch=60, lrate=0.100, error=393.799\n",
      ">epoch=61, lrate=0.100, error=393.802\n",
      ">epoch=62, lrate=0.100, error=393.805\n",
      ">epoch=63, lrate=0.100, error=393.808\n",
      ">epoch=64, lrate=0.100, error=393.811\n",
      ">epoch=65, lrate=0.100, error=393.814\n",
      ">epoch=66, lrate=0.100, error=393.817\n",
      ">epoch=67, lrate=0.100, error=393.819\n",
      ">epoch=68, lrate=0.100, error=393.822\n",
      ">epoch=69, lrate=0.100, error=393.824\n",
      ">epoch=70, lrate=0.100, error=393.827\n",
      ">epoch=71, lrate=0.100, error=393.829\n",
      ">epoch=72, lrate=0.100, error=393.831\n",
      ">epoch=73, lrate=0.100, error=393.834\n",
      ">epoch=74, lrate=0.100, error=393.836\n",
      ">epoch=75, lrate=0.100, error=393.838\n",
      ">epoch=76, lrate=0.100, error=393.840\n",
      ">epoch=77, lrate=0.100, error=393.842\n",
      ">epoch=78, lrate=0.100, error=393.844\n",
      ">epoch=79, lrate=0.100, error=393.846\n",
      ">epoch=80, lrate=0.100, error=393.848\n",
      ">epoch=81, lrate=0.100, error=393.850\n",
      ">epoch=82, lrate=0.100, error=393.851\n",
      ">epoch=83, lrate=0.100, error=393.853\n",
      ">epoch=84, lrate=0.100, error=393.855\n",
      ">epoch=85, lrate=0.100, error=393.856\n",
      ">epoch=86, lrate=0.100, error=393.858\n",
      ">epoch=87, lrate=0.100, error=393.860\n",
      ">epoch=88, lrate=0.100, error=393.861\n",
      ">epoch=89, lrate=0.100, error=393.863\n",
      ">epoch=90, lrate=0.100, error=393.864\n",
      ">epoch=91, lrate=0.100, error=393.866\n",
      ">epoch=92, lrate=0.100, error=393.867\n",
      ">epoch=93, lrate=0.100, error=393.868\n",
      ">epoch=94, lrate=0.100, error=393.870\n",
      ">epoch=95, lrate=0.100, error=393.871\n",
      ">epoch=96, lrate=0.100, error=393.872\n",
      ">epoch=97, lrate=0.100, error=393.874\n",
      ">epoch=98, lrate=0.100, error=393.875\n",
      ">epoch=99, lrate=0.100, error=393.876\n",
      ">epoch=0, lrate=0.100, error=326.414\n",
      ">epoch=1, lrate=0.100, error=385.696\n",
      ">epoch=2, lrate=0.100, error=389.906\n",
      ">epoch=3, lrate=0.100, error=391.474\n",
      ">epoch=4, lrate=0.100, error=392.299\n",
      ">epoch=5, lrate=0.100, error=392.809\n",
      ">epoch=6, lrate=0.100, error=393.156\n",
      ">epoch=7, lrate=0.100, error=393.407\n",
      ">epoch=8, lrate=0.100, error=393.597\n",
      ">epoch=9, lrate=0.100, error=393.747\n",
      ">epoch=10, lrate=0.100, error=393.867\n",
      ">epoch=11, lrate=0.100, error=393.966\n",
      ">epoch=12, lrate=0.100, error=394.049\n",
      ">epoch=13, lrate=0.100, error=394.120\n",
      ">epoch=14, lrate=0.100, error=394.181\n",
      ">epoch=15, lrate=0.100, error=394.233\n",
      ">epoch=16, lrate=0.100, error=394.280\n",
      ">epoch=17, lrate=0.100, error=394.321\n",
      ">epoch=18, lrate=0.100, error=394.357\n",
      ">epoch=19, lrate=0.100, error=394.390\n",
      ">epoch=20, lrate=0.100, error=394.419\n",
      ">epoch=21, lrate=0.100, error=394.446\n",
      ">epoch=22, lrate=0.100, error=394.471\n",
      ">epoch=23, lrate=0.100, error=394.493\n",
      ">epoch=24, lrate=0.100, error=394.513\n",
      ">epoch=25, lrate=0.100, error=394.532\n",
      ">epoch=26, lrate=0.100, error=394.550\n",
      ">epoch=27, lrate=0.100, error=394.566\n",
      ">epoch=28, lrate=0.100, error=394.581\n",
      ">epoch=29, lrate=0.100, error=394.595\n",
      ">epoch=30, lrate=0.100, error=394.608\n",
      ">epoch=31, lrate=0.100, error=394.620\n",
      ">epoch=32, lrate=0.100, error=394.632\n",
      ">epoch=33, lrate=0.100, error=394.643\n",
      ">epoch=34, lrate=0.100, error=394.653\n",
      ">epoch=35, lrate=0.100, error=394.663\n",
      ">epoch=36, lrate=0.100, error=394.672\n",
      ">epoch=37, lrate=0.100, error=394.680\n",
      ">epoch=38, lrate=0.100, error=394.688\n",
      ">epoch=39, lrate=0.100, error=394.696\n",
      ">epoch=40, lrate=0.100, error=394.704\n",
      ">epoch=41, lrate=0.100, error=394.711\n",
      ">epoch=42, lrate=0.100, error=394.717\n",
      ">epoch=43, lrate=0.100, error=394.724\n",
      ">epoch=44, lrate=0.100, error=394.730\n",
      ">epoch=45, lrate=0.100, error=394.736\n",
      ">epoch=46, lrate=0.100, error=394.741\n",
      ">epoch=47, lrate=0.100, error=394.747\n",
      ">epoch=48, lrate=0.100, error=394.752\n",
      ">epoch=49, lrate=0.100, error=394.757\n",
      ">epoch=50, lrate=0.100, error=394.761\n",
      ">epoch=51, lrate=0.100, error=394.766\n",
      ">epoch=52, lrate=0.100, error=394.770\n",
      ">epoch=53, lrate=0.100, error=394.775\n",
      ">epoch=54, lrate=0.100, error=394.779\n",
      ">epoch=55, lrate=0.100, error=394.783\n",
      ">epoch=56, lrate=0.100, error=394.786\n",
      ">epoch=57, lrate=0.100, error=394.790\n",
      ">epoch=58, lrate=0.100, error=394.793\n",
      ">epoch=59, lrate=0.100, error=394.797\n",
      ">epoch=60, lrate=0.100, error=394.800\n",
      ">epoch=61, lrate=0.100, error=394.803\n",
      ">epoch=62, lrate=0.100, error=394.806\n",
      ">epoch=63, lrate=0.100, error=394.809\n",
      ">epoch=64, lrate=0.100, error=394.812\n",
      ">epoch=65, lrate=0.100, error=394.815\n",
      ">epoch=66, lrate=0.100, error=394.818\n",
      ">epoch=67, lrate=0.100, error=394.820\n",
      ">epoch=68, lrate=0.100, error=394.823\n",
      ">epoch=69, lrate=0.100, error=394.826\n",
      ">epoch=70, lrate=0.100, error=394.828\n",
      ">epoch=71, lrate=0.100, error=394.830\n",
      ">epoch=72, lrate=0.100, error=394.833\n",
      ">epoch=73, lrate=0.100, error=394.835\n",
      ">epoch=74, lrate=0.100, error=394.837\n",
      ">epoch=75, lrate=0.100, error=394.839\n",
      ">epoch=76, lrate=0.100, error=394.841\n",
      ">epoch=77, lrate=0.100, error=394.843\n",
      ">epoch=78, lrate=0.100, error=394.845\n",
      ">epoch=79, lrate=0.100, error=394.847\n",
      ">epoch=80, lrate=0.100, error=394.849\n",
      ">epoch=81, lrate=0.100, error=394.851\n",
      ">epoch=82, lrate=0.100, error=394.852\n",
      ">epoch=83, lrate=0.100, error=394.854\n",
      ">epoch=84, lrate=0.100, error=394.856\n",
      ">epoch=85, lrate=0.100, error=394.858\n",
      ">epoch=86, lrate=0.100, error=394.859\n",
      ">epoch=87, lrate=0.100, error=394.861\n",
      ">epoch=88, lrate=0.100, error=394.862\n",
      ">epoch=89, lrate=0.100, error=394.864\n",
      ">epoch=90, lrate=0.100, error=394.865\n",
      ">epoch=91, lrate=0.100, error=394.867\n",
      ">epoch=92, lrate=0.100, error=394.868\n",
      ">epoch=93, lrate=0.100, error=394.869\n",
      ">epoch=94, lrate=0.100, error=394.871\n",
      ">epoch=95, lrate=0.100, error=394.872\n",
      ">epoch=96, lrate=0.100, error=394.873\n",
      ">epoch=97, lrate=0.100, error=394.875\n",
      ">epoch=98, lrate=0.100, error=394.876\n",
      ">epoch=99, lrate=0.100, error=394.877\n",
      ">epoch=0, lrate=0.100, error=334.089\n",
      ">epoch=1, lrate=0.100, error=393.720\n",
      ">epoch=2, lrate=0.100, error=397.911\n",
      ">epoch=3, lrate=0.100, error=399.476\n",
      ">epoch=4, lrate=0.100, error=400.299\n",
      ">epoch=5, lrate=0.100, error=400.808\n",
      ">epoch=6, lrate=0.100, error=401.155\n",
      ">epoch=7, lrate=0.100, error=401.406\n",
      ">epoch=8, lrate=0.100, error=401.596\n",
      ">epoch=9, lrate=0.100, error=401.746\n",
      ">epoch=10, lrate=0.100, error=401.866\n",
      ">epoch=11, lrate=0.100, error=401.965\n",
      ">epoch=12, lrate=0.100, error=402.048\n",
      ">epoch=13, lrate=0.100, error=402.119\n",
      ">epoch=14, lrate=0.100, error=402.180\n",
      ">epoch=15, lrate=0.100, error=402.232\n",
      ">epoch=16, lrate=0.100, error=402.279\n",
      ">epoch=17, lrate=0.100, error=402.320\n",
      ">epoch=18, lrate=0.100, error=402.356\n",
      ">epoch=19, lrate=0.100, error=402.389\n",
      ">epoch=20, lrate=0.100, error=402.419\n",
      ">epoch=21, lrate=0.100, error=402.446\n",
      ">epoch=22, lrate=0.100, error=402.470\n",
      ">epoch=23, lrate=0.100, error=402.492\n",
      ">epoch=24, lrate=0.100, error=402.513\n",
      ">epoch=25, lrate=0.100, error=402.532\n",
      ">epoch=26, lrate=0.100, error=402.549\n",
      ">epoch=27, lrate=0.100, error=402.565\n",
      ">epoch=28, lrate=0.100, error=402.580\n",
      ">epoch=29, lrate=0.100, error=402.594\n",
      ">epoch=30, lrate=0.100, error=402.608\n",
      ">epoch=31, lrate=0.100, error=402.620\n",
      ">epoch=32, lrate=0.100, error=402.631\n",
      ">epoch=33, lrate=0.100, error=402.642\n",
      ">epoch=34, lrate=0.100, error=402.652\n",
      ">epoch=35, lrate=0.100, error=402.662\n",
      ">epoch=36, lrate=0.100, error=402.671\n",
      ">epoch=37, lrate=0.100, error=402.680\n",
      ">epoch=38, lrate=0.100, error=402.688\n",
      ">epoch=39, lrate=0.100, error=402.696\n",
      ">epoch=40, lrate=0.100, error=402.703\n",
      ">epoch=41, lrate=0.100, error=402.710\n",
      ">epoch=42, lrate=0.100, error=402.717\n",
      ">epoch=43, lrate=0.100, error=402.723\n",
      ">epoch=44, lrate=0.100, error=402.729\n",
      ">epoch=45, lrate=0.100, error=402.735\n",
      ">epoch=46, lrate=0.100, error=402.741\n",
      ">epoch=47, lrate=0.100, error=402.746\n",
      ">epoch=48, lrate=0.100, error=402.751\n",
      ">epoch=49, lrate=0.100, error=402.756\n",
      ">epoch=50, lrate=0.100, error=402.761\n",
      ">epoch=51, lrate=0.100, error=402.765\n",
      ">epoch=52, lrate=0.100, error=402.770\n",
      ">epoch=53, lrate=0.100, error=402.774\n",
      ">epoch=54, lrate=0.100, error=402.778\n",
      ">epoch=55, lrate=0.100, error=402.782\n",
      ">epoch=56, lrate=0.100, error=402.786\n",
      ">epoch=57, lrate=0.100, error=402.789\n",
      ">epoch=58, lrate=0.100, error=402.793\n",
      ">epoch=59, lrate=0.100, error=402.796\n",
      ">epoch=60, lrate=0.100, error=402.800\n",
      ">epoch=61, lrate=0.100, error=402.803\n",
      ">epoch=62, lrate=0.100, error=402.806\n",
      ">epoch=63, lrate=0.100, error=402.809\n",
      ">epoch=64, lrate=0.100, error=402.812\n",
      ">epoch=65, lrate=0.100, error=402.815\n",
      ">epoch=66, lrate=0.100, error=402.817\n",
      ">epoch=67, lrate=0.100, error=402.820\n",
      ">epoch=68, lrate=0.100, error=402.823\n",
      ">epoch=69, lrate=0.100, error=402.825\n",
      ">epoch=70, lrate=0.100, error=402.828\n",
      ">epoch=71, lrate=0.100, error=402.830\n",
      ">epoch=72, lrate=0.100, error=402.832\n",
      ">epoch=73, lrate=0.100, error=402.834\n",
      ">epoch=74, lrate=0.100, error=402.837\n",
      ">epoch=75, lrate=0.100, error=402.839\n",
      ">epoch=76, lrate=0.100, error=402.841\n",
      ">epoch=77, lrate=0.100, error=402.843\n",
      ">epoch=78, lrate=0.100, error=402.845\n",
      ">epoch=79, lrate=0.100, error=402.847\n",
      ">epoch=80, lrate=0.100, error=402.849\n",
      ">epoch=81, lrate=0.100, error=402.850\n",
      ">epoch=82, lrate=0.100, error=402.852\n",
      ">epoch=83, lrate=0.100, error=402.854\n",
      ">epoch=84, lrate=0.100, error=402.856\n",
      ">epoch=85, lrate=0.100, error=402.857\n",
      ">epoch=86, lrate=0.100, error=402.859\n",
      ">epoch=87, lrate=0.100, error=402.860\n",
      ">epoch=88, lrate=0.100, error=402.862\n",
      ">epoch=89, lrate=0.100, error=402.863\n",
      ">epoch=90, lrate=0.100, error=402.865\n",
      ">epoch=91, lrate=0.100, error=402.866\n",
      ">epoch=92, lrate=0.100, error=402.868\n",
      ">epoch=93, lrate=0.100, error=402.869\n",
      ">epoch=94, lrate=0.100, error=402.871\n",
      ">epoch=95, lrate=0.100, error=402.872\n",
      ">epoch=96, lrate=0.100, error=402.873\n",
      ">epoch=97, lrate=0.100, error=402.874\n",
      ">epoch=98, lrate=0.100, error=402.876\n",
      ">epoch=99, lrate=0.100, error=402.877\n",
      ">epoch=0, lrate=0.100, error=333.190\n",
      ">epoch=1, lrate=0.100, error=392.745\n",
      ">epoch=2, lrate=0.100, error=396.930\n",
      ">epoch=3, lrate=0.100, error=398.490\n",
      ">epoch=4, lrate=0.100, error=399.311\n",
      ">epoch=5, lrate=0.100, error=399.819\n",
      ">epoch=6, lrate=0.100, error=400.164\n",
      ">epoch=7, lrate=0.100, error=400.415\n",
      ">epoch=8, lrate=0.100, error=400.604\n",
      ">epoch=9, lrate=0.100, error=400.753\n",
      ">epoch=10, lrate=0.100, error=400.873\n",
      ">epoch=11, lrate=0.100, error=400.972\n",
      ">epoch=12, lrate=0.100, error=401.054\n",
      ">epoch=13, lrate=0.100, error=401.125\n",
      ">epoch=14, lrate=0.100, error=401.185\n",
      ">epoch=15, lrate=0.100, error=401.238\n",
      ">epoch=16, lrate=0.100, error=401.284\n",
      ">epoch=17, lrate=0.100, error=401.325\n",
      ">epoch=18, lrate=0.100, error=401.361\n",
      ">epoch=19, lrate=0.100, error=401.394\n",
      ">epoch=20, lrate=0.100, error=401.423\n",
      ">epoch=21, lrate=0.100, error=401.450\n",
      ">epoch=22, lrate=0.100, error=401.474\n",
      ">epoch=23, lrate=0.100, error=401.496\n",
      ">epoch=24, lrate=0.100, error=401.517\n",
      ">epoch=25, lrate=0.100, error=401.535\n",
      ">epoch=26, lrate=0.100, error=401.553\n",
      ">epoch=27, lrate=0.100, error=401.569\n",
      ">epoch=28, lrate=0.100, error=401.584\n",
      ">epoch=29, lrate=0.100, error=401.598\n",
      ">epoch=30, lrate=0.100, error=401.611\n",
      ">epoch=31, lrate=0.100, error=401.623\n",
      ">epoch=32, lrate=0.100, error=401.634\n",
      ">epoch=33, lrate=0.100, error=401.645\n",
      ">epoch=34, lrate=0.100, error=401.655\n",
      ">epoch=35, lrate=0.100, error=401.665\n",
      ">epoch=36, lrate=0.100, error=401.674\n",
      ">epoch=37, lrate=0.100, error=401.683\n",
      ">epoch=38, lrate=0.100, error=401.691\n",
      ">epoch=39, lrate=0.100, error=401.698\n",
      ">epoch=40, lrate=0.100, error=401.706\n",
      ">epoch=41, lrate=0.100, error=401.713\n",
      ">epoch=42, lrate=0.100, error=401.719\n",
      ">epoch=43, lrate=0.100, error=401.726\n",
      ">epoch=44, lrate=0.100, error=401.732\n",
      ">epoch=45, lrate=0.100, error=401.738\n",
      ">epoch=46, lrate=0.100, error=401.743\n",
      ">epoch=47, lrate=0.100, error=401.748\n",
      ">epoch=48, lrate=0.100, error=401.754\n",
      ">epoch=49, lrate=0.100, error=401.758\n",
      ">epoch=50, lrate=0.100, error=401.763\n",
      ">epoch=51, lrate=0.100, error=401.768\n",
      ">epoch=52, lrate=0.100, error=401.772\n",
      ">epoch=53, lrate=0.100, error=401.776\n",
      ">epoch=54, lrate=0.100, error=401.780\n",
      ">epoch=55, lrate=0.100, error=401.784\n",
      ">epoch=56, lrate=0.100, error=401.788\n",
      ">epoch=57, lrate=0.100, error=401.792\n",
      ">epoch=58, lrate=0.100, error=401.795\n",
      ">epoch=59, lrate=0.100, error=401.798\n",
      ">epoch=60, lrate=0.100, error=401.802\n",
      ">epoch=61, lrate=0.100, error=401.805\n",
      ">epoch=62, lrate=0.100, error=401.808\n",
      ">epoch=63, lrate=0.100, error=401.811\n",
      ">epoch=64, lrate=0.100, error=401.814\n",
      ">epoch=65, lrate=0.100, error=401.817\n",
      ">epoch=66, lrate=0.100, error=401.819\n",
      ">epoch=67, lrate=0.100, error=401.822\n",
      ">epoch=68, lrate=0.100, error=401.824\n",
      ">epoch=69, lrate=0.100, error=401.827\n",
      ">epoch=70, lrate=0.100, error=401.829\n",
      ">epoch=71, lrate=0.100, error=401.832\n",
      ">epoch=72, lrate=0.100, error=401.834\n",
      ">epoch=73, lrate=0.100, error=401.836\n",
      ">epoch=74, lrate=0.100, error=401.838\n",
      ">epoch=75, lrate=0.100, error=401.840\n",
      ">epoch=76, lrate=0.100, error=401.842\n",
      ">epoch=77, lrate=0.100, error=401.844\n",
      ">epoch=78, lrate=0.100, error=401.846\n",
      ">epoch=79, lrate=0.100, error=401.848\n",
      ">epoch=80, lrate=0.100, error=401.850\n",
      ">epoch=81, lrate=0.100, error=401.852\n",
      ">epoch=82, lrate=0.100, error=401.854\n",
      ">epoch=83, lrate=0.100, error=401.855\n",
      ">epoch=84, lrate=0.100, error=401.857\n",
      ">epoch=85, lrate=0.100, error=401.859\n",
      ">epoch=86, lrate=0.100, error=401.860\n",
      ">epoch=87, lrate=0.100, error=401.862\n",
      ">epoch=88, lrate=0.100, error=401.863\n",
      ">epoch=89, lrate=0.100, error=401.865\n",
      ">epoch=90, lrate=0.100, error=401.866\n",
      ">epoch=91, lrate=0.100, error=401.868\n",
      ">epoch=92, lrate=0.100, error=401.869\n",
      ">epoch=93, lrate=0.100, error=401.871\n",
      ">epoch=94, lrate=0.100, error=401.872\n",
      ">epoch=95, lrate=0.100, error=401.873\n",
      ">epoch=96, lrate=0.100, error=401.875\n",
      ">epoch=97, lrate=0.100, error=401.876\n",
      ">epoch=98, lrate=0.100, error=401.877\n",
      ">epoch=99, lrate=0.100, error=401.878\n",
      "Scores: [0.0, 0.0, 100.0, 0.0, 0.0]\n",
      "Mean Accuracy: 20.000%\n"
     ]
    }
   ],
   "source": [
    "# test the algorithm\n",
    "filename = \"pima-indians-diabetes.csv\"\n",
    "dataset = load_csv(filename)\n",
    "for i in range(len(dataset[0])):\n",
    "    str_column_to_float(dataset, i)\n",
    "\n",
    "    \n",
    "# normalize\n",
    "minmax = dataset_minmax(dataset)\n",
    "normalize_dataset(dataset, minmax)\n",
    "\n",
    "\n",
    "# evaluate algorithm\n",
    "n_folds = 5\n",
    "l_rate = 0.1\n",
    "n_epoch = 100\n",
    "\n",
    "scores = evaluate_algorithm(dataset, logistic_regression, n_folds, l_rate, n_epoch)\n",
    "print('Scores: %s' % scores)\n",
    "print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
